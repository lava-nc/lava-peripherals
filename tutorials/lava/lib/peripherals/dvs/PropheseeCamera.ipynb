{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21d15919-bad4-4363-b458-520b30510ca5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Prophesee Event Camera \n",
    "\n",
    "In this tutorial we demonstrate how to stream event-based data from a Prophesee camera (or recording) into Lava. We show the basic usage of the `PropheseeCamera` Process and how to apply filters and transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1df6eded-4456-406f-b5b9-bab9bc7c687a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from lava.magma.core.run_configs import Loihi2SimCfg\n",
    "from lava.magma.core.run_conditions import RunSteps\n",
    "\n",
    "from lava.lib.peripherals.dvs.prophesee import PropheseeCamera\n",
    "\n",
    "from utils import EventVisualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e456b29-9503-4546-adc7-37c8d511dcf3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Download raw event recording\n",
    "\n",
    "Open the RAW event data file. If the file does not exist, it will be downloaded from Prophesee's public sample server.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "602de9c0-4501-42b3-b604-589346b82b19",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import metavision_core as mv\n",
    "\n",
    "EVENT_RECORDING_FILENAME = \"80_balls.raw\"\n",
    "mv.utils.get_sample(EVENT_RECORDING_FILENAME)\n",
    "\n",
    "reader = mv.event_io.RawReader(EVENT_RECORDING_FILENAME)\n",
    "height, width = reader.get_size()\n",
    "del reader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c02f60",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Basic usage\n",
    "\n",
    "The `PropheseeCamera` Process can be used to stream from a Prophesee camera or to stream from a recording. To stream from a recording, specify the file name and path in the `filename` parameter. To stream from a camera, do not specify the parameter or set it to an empty string (\"\").\n",
    "\n",
    "The output of the `PropheseeCamera` is an event histogram over all pixels, holding the number of events per pixel. By specifying the optional `num_output_time_bins` parameter, the output histogram can be sliced into time bins (default is 1).\n",
    "\n",
    "The example below visualizes the events from a sample recording of a Prophesee camera that shows falling balls. On-events are visualized in green and off-events in purple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2350b58f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Initialize Processes\n",
    "camera = PropheseeCamera(filename=EVENT_RECORDING_FILENAME,\n",
    "                         sensor_shape=(height, width))\n",
    "\n",
    "event_visualizer = EventVisualizer(shape=camera.s_out.shape)\n",
    "\n",
    "# Connect\n",
    "camera.s_out.connect(event_visualizer.s_in)\n",
    "\n",
    "# Run\n",
    "num_steps = 200\n",
    "run_cfg = Loihi2SimCfg()\n",
    "run_cnd = RunSteps(num_steps=num_steps)\n",
    "\n",
    "camera.run(condition=run_cnd, run_cfg=run_cfg)\n",
    "camera.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce58b691",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "<table>\n",
    "<tr>\n",
    "    <td> <img src=\"gifs/basic.gif\" alt=\"Drawing\" style=\"height: 250px;\"/> </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af74e95",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Apply filters\n",
    "\n",
    "The `PropheseeCamera` Process can preprocess event-based data using filters from the metavision_sdk. For instance, the falling balls in the recording cause a trail of events. Such trails often cause undesirable blurring of moving objects in the scene. In the example below, such trails are reduced by applying the `TrailFilterAlgorithm` from the metavision_sdk. The difference is subtly visible by the change in color, in which the events are visualized. Refer to the metavision documentation for more filters and their usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11070d6f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from metavision_sdk_cv import TrailFilterAlgorithm, ActivityNoiseFilterAlgorithm\n",
    "\n",
    "\n",
    "filters = [TrailFilterAlgorithm(width=width, height=height, threshold=100000),\n",
    "           ActivityNoiseFilterAlgorithm(width=width, height=height, threshold=1000),]\n",
    "\n",
    "\n",
    "# Initialize Processes\n",
    "camera = PropheseeCamera(filename=EVENT_RECORDING_FILENAME,\n",
    "                         filters=filters,\n",
    "                         sensor_shape=(height, width))\n",
    "\n",
    "event_visualizer = EventVisualizer(shape=camera.s_out.shape)\n",
    "\n",
    "# Connect\n",
    "camera.s_out.connect(event_visualizer.s_in)\n",
    "\n",
    "# Run\n",
    "num_steps = 200\n",
    "run_cfg = Loihi2SimCfg()\n",
    "run_cnd = RunSteps(num_steps=num_steps)\n",
    "\n",
    "camera.run(condition=run_cnd, run_cfg=run_cfg)\n",
    "camera.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8a505a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "<table>\n",
    "<tr>\n",
    "    <td> <img src=\"gifs/filters.gif\" alt=\"Drawing\" style=\"height: 250px;\"/> </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc0dd7c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Apply transformations\n",
    "\n",
    "Lava-peripherals includes transformations that can be applied to the event data, for instance down-sampling, merging of polarities, and mirroring.\n",
    "In the example below, the original output is down-sampled, reducing the original resolution by one half."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2353426",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from lava.lib.peripherals.dvs.transformation import Compose, Downsample\n",
    "\n",
    "transformations = Compose(\n",
    "    [\n",
    "        Downsample(factor=0.5),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Initialize Processes\n",
    "camera = PropheseeCamera(filename=EVENT_RECORDING_FILENAME,\n",
    "                              transformations=transformations,\n",
    "                              sensor_shape=(height, width),\n",
    "                              num_output_time_bins=1)\n",
    "\n",
    "event_visualizer = EventVisualizer(shape=camera.s_out.shape)\n",
    "\n",
    "# Connect\n",
    "camera.s_out.connect(event_visualizer.s_in)\n",
    "\n",
    "# Run\n",
    "num_steps = 200\n",
    "run_cfg = Loihi2SimCfg()\n",
    "run_cnd = RunSteps(num_steps=num_steps)\n",
    "\n",
    "camera.run(condition=run_cnd, run_cfg=run_cfg)\n",
    "camera.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f689da0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "<table>\n",
    "<tr>\n",
    "    <td> <img src=\"gifs/transform.gif\" alt=\"Drawing\" style=\"height: 125px;\"/> </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8331eb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Custom transformation and manual output shape\n",
    "\n",
    "The implementation of transformations is compatible with the transformations from both tonic and torchvision. Please refer to the tonic documentation to see a complete [list of available transformations and their usage](https://tonic.readthedocs.io/en/latest/auto_examples/index.html). If you need to use custom transformation, the output shape of the Process can not be determined automatically. In that case, you need to specify the output shape manually.\n",
    "\n",
    "In the example below, the custom transformation `right_shift_along_x` shifts all events to the right on the x-axis by 500 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8da0e998",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def right_shift_along_x(events):\n",
    "    events['x'] += 500\n",
    "    return events\n",
    "    \n",
    "\n",
    "transformations = Compose(\n",
    "    [\n",
    "        right_shift_along_x,\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Initialize Processes\n",
    "camera = PropheseeCamera(filename=EVENT_RECORDING_FILENAME,\n",
    "                         transformations=transformations,\n",
    "                         sensor_shape=(height, width),\n",
    "                         out_shape=(1, 2, height, width+500))\n",
    "\n",
    "event_visualizer = EventVisualizer(shape=camera.s_out.shape)\n",
    "\n",
    "# Connect\n",
    "camera.s_out.connect(event_visualizer.s_in)\n",
    "\n",
    "# Run\n",
    "num_steps = 200\n",
    "run_cfg = Loihi2SimCfg()\n",
    "run_cnd = RunSteps(num_steps=num_steps)\n",
    "\n",
    "camera.run(condition=run_cnd, run_cfg=run_cfg)\n",
    "camera.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6960265b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "<table>\n",
    "<tr>\n",
    "    <td> <img src=\"gifs/custom_trans.gif\" alt=\"Drawing\" style=\"height: 250px;\"/> </td>\n",
    "</tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
